# Train long-context LLM with "paraphrasing the original text"

* ðŸ’» training script (QLora): `train_with_paraphrasing.py`
* ðŸ“„[Paper](https://arxiv.org/abs/2312.11193)
* ðŸ“š[Dataset Download](https://huggingface.co/datasets/yuyijiong/Long-Instruction-with-Paraphrasing)

## ðŸ¦™ Trained models 
continuously updating...

|model|link|
|---|---|
|llama3-8b-chinese-chat-32k| [link](https://huggingface.co/yuyijiong/llama3-8b-chinese-chat-32k)|
|Qwen-14b-chat-yarn-32k|[link](https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k)|
|Qwen1.5-4b-chat-paraph|[link](https://huggingface.co/yuyijiong/Qwen1.5-4b-chat-paraph)|
